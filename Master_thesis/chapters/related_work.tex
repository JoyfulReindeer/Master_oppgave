\chapter{Related Work}

%Structure Literature Review
\section{HOW TO WRITE THIS SHIT}
The structure of a literature review
A literature review should be structured like any other essay: it should have an introduction, a middle or main body, and a conclusion.
\\Introduction
\\The introduction should:
\begin{itemize}
    \item GAPS
    \item Define your topic and provide an appropriate context for reviewing the literature;
    \item Establish your reasons – i.e. point of view – for reviewing the literature;
    \item Explain the organisation – i.e. sequence – of the review;
    \item State the scope of the review – i.e. what is included and what isn’t included. For example, if you were reviewing the literature on obesity in children you might say something like: There are a large number of studies of obesity trends in the general population. However, since the focus of this research is on obesity in children, these will not be reviewed in detail and will only be referred to as appropriate.
\end{itemize}

Main body
The middle or main body should:

\begin{itemize}
    \item Organise the literature according to common themes;
    \item Provide insight into the relation between your chosen topic and the wider subject area e.g. between obesity in children and obesity in general;
    \item Move from a general, wider view of the literature being reviewed to the specific focus of your research.
\end{itemize}

Conclusion
The conclusion should:
\begin{itemize}
    \item Summarise the important aspects of the existing body of literature;
    \item Evaluate the current state of the literature reviewed;
    \item Identify significant flaws or gaps in existing knowledge;
    \item Outline areas for future study;
    \item Link your research to existing knowledge.
\end{itemize}
\newpage

% --INTRODUCTION--
\section{Introduction}
Comparison of the user experience of a virtual assistant (e.g Google Assistant) and a robot assistant (Eg. Pepper). In this case the user experience is classified as communication and accessibility with the device. With communication we are referring to its inputs and outputs, and with accessibility we are referring to how the information is translated to the user of the device. There will also be some focus on the acceptance of a virtual assistant and a robot assistant among the users are.

Proposed research questions: 

How is the user expereince of Pepper compared to Google Assistant? 

How accessible is Pepper compared to Google Assistant?  t

What can Pepper do that Google Assistant can not do? / What can Google Assistant do that Pepper can not do? 

Dermed blir vårt «Study Focus» å sammenligne brukervennlighet i multimodalitet når det kommer til både «humanoid/social roboter» og «stemmebaserte brukergrensesnitt med skjermer», og dermed blir multimodalitet det emne vi skal bli eksperter på gjennom masteren.

\section{Clarification of Terms}
There are multiple terms going around (...)To distinguish between Pepper and Google Assistant we will use the terms Robot Assistand and Virtual Assistant. (...) We will focus på Multimodal User Interface as the term for the interaction between both VA and RA, and a user.
%kanskje bare si hva det blir kalt i de forskjellige artiklene, og at vi bruker paraplybegreper lzm 

% --Body--
% MULTIMODALITET, GOOGLE ASSISTAT, VIRTUELL ASSISTANT, PEPPER, ROBOT ASSISTANT, PAST DONE, FUTURE WOULD LOOK LIKE, HOW OUR CAN HELP THE GAP 
% HVA ER DET PEPPER HAR BLITT BRUKT TIL TIDLIGERE
% HAR VI NOEN SPESIELLE KEY FINDINGS? NOE VI MÅ PUNKTERE FRAM? 
%(Kanksje tidligere sammenligninger av alexa, google assistant også videre - for å vise hvordan det     kan gjøres?) 
\section{Related work}

\subsection{Multimodal user interface}
Multimodal Interface is described as an interactive system that uses more than one way of interaction and feedback. This can be speech, gestures, smell, facial expressions and more. \cite{turk.m}

There are multiple advantages of MUI \cite{turk.m}; 
\begin{itemize}
    \item It is flexible because of multiple input modes and gives the user the chance to decide what type of input mode that should be used. This again can improve its efficiency.  
    \item It improves accessibility among the users. This means that both one that has sprained their wrist can use their voice to take notes, and if one has movement impairments one can use their voice to take notes. 
    \item If one comes across an error it might be easier to figure out how and why through one of the other inputs if one did not understand it through the given input. 
\end{itemize}

\subsubsection{Guidelines for Multimodal User Interface Design} 
L. M. Reeves et. al. \cite{reeves.lm} published in 2004 a research paper with a set of guidelines for multimodal user interfaces. This will also, in my opinion, explain why it is important to focus on MUI design when designing a conversational agent. Since this paper is from 2004 one can imagine and understand how new Multimodal Interface is.  There are six guidelines that were presented in the research paper from L. M. Reeves et. al. \cite{reeves.lm}; 

\textbf{Requirement specification.}
There are two requirements when designing. One is two take all users into consideration when designing a system. This means that your design has to be compatible with different types of users. The other is to take both privacy and securtity issues into consideraton. The user should be notified in some way what they are signing up for. 

\textbf{Designing Multimodal Input and Output.}
This guideline means that there should be multiple ways of making an  input to the device and that the device can give output accordingly. 
This also means that if a person has hearing impairments, they have the possibility to type in and get a written respond back. Just as a person with visual impairments can use their voice and get a “vocal” respond back.
However, this is not only an advantage to people with impairments, it can also be helpful for those that are temporarily losing one of their senses; such as when one is driving a car and can just ask Siri to play a song. 

\textbf{Adaptivity.} 
Adaptivity focuses also on users. This means, in short, that the device should be able to adapt to the user. 

\textbf{Consistency.} 
This guideline refers to how the VUI and GUI should co-operate and give more or less the same feedback. Which means that there should be a consistency feedback between the user interface and the conversational agent. 

\textbf{Feedback.} 
Again, the feedback should be made to the user in different modalities. This means that a user has the possibility to see the same feedback in both an interface and hear it by the conversational agent. 

\textbf{Error Prevention/Handling.} 
The multimodal device should be able to prevent an error for happening. Of course, errors might occur, but it should be flexible enough to give the user feedback/output as to why and how to fix it in the modality that is most useful for the user. 

\subsection{Accessibility/Usability}
%Brukervennlighet; hva det er viktig å fokusere på? (Kanksje droppe) 

\subsection{Virtual Assistant(s) and ranges of utilization}
Virtual assistants (VA) are becoming a part of our everyday life. One can interact with them in one's cellphone, computer, smart speakers, smart home, and more. In these days the most common once are Siri from Apple, Google Assistant from Google, Alexa from Amazon, and Cortana from Microsoft. \cite{Berdasco.A, Hoy.M} %Denne er til hele avsnittet. 

One of VAs most important roles are to make complex tasks more efficient and user friendly for the user \cite{Corbett.E}. This means that the user will use their natural way of interacting with the VA (eg. voice instead of touch)\cite{Neto.AT}. An voice-based interaction can result in a hands-free interaction if you are in a moving  car, or help visually impaired persons with executing a task \cite{pyae.a} 
. Such behaviour can %Endre: Increase thee task completion rates, reduce time and effort, and improve users' satisfication rates \cite{Corbett.E}. 

%Notater
\textbf{ What it can do and IFTTT-statements - Good morning = lights on, starting the coffeee machine etc.} 
\textbf{Voice assistants have the potential to radically change how the users interact with computers. For many ysers, the ability to read and type is a barrier to accessing information. Voice assistant can bridge the infomration gap for those users.}
\cite{Hoy.M}
%Notater

A virtual assistant is made up of an artificial intelligence and algorithms \cite{Fry.H}. Hannah Fry \cite{Fry.H} made up four categories of how algorithms works (own translation) : Priority: make an organized list, Classification: choose a category, Association: find connection, and Filtering: isolate the most important. 

%Få inn bruksområder her /Range of Utilization Evt egen subsection? 

%under MUI?? Se på dette
Virtual assistants mostly consists of a multimodal user interface, but within MUI one has the terms; Graphical User Interface (GUI), Voice User Interface (VUI), and  Natural User Interface (NUI);

\textbf{Graphical User Interface} is when the user interacts with a desktop \cite{Interaction-Design-Foundation-GUI}. This can be experienced on a computer's desktop, tablet and mobile's desktop \cite{Interaction-Design-Foundation-GUI}. In this case it can be the mobile application for one of the virtual assistants. 
 
\textbf{Voice User Interface} is when when the user interacts with a voice-based interface \cite{Interaction-Design-Foundation-VUI}. In this case it can be when the user is interacting with a smart speaker – this also foresees that the user do not necessarily use another interface, that in most cases are available, in the process.  
 
\textbf{Natural User Interface} is when the user interacts in a natural way – This can be voice, gestures, and touch \cite{Interaction-Design-Foundation-NUI}. However, it is not only about the users preferences, it is also about how the virtual assistant interacts back \cite{Interaction-Design-Foundation-NUI}; 
 \begin{itemize}
     \item Does the device have an \textbf{Instant Expertise}? This meaning that the device has taken the user's existing expertise, eg. common communication skill, into consideration. 
     \item Does the device give \textbf{Progress Learning}? This meaning that the device can explain how to be used and its possibilities. In other words there is a learning path where one can explore more within the deivce. 
     \item Does the device have a \textbf{Direct Interaction}? This meaning that the user can interact in a way that feels natural, eg. through motion sensors.
     \item Does the device give less \textbf{Cognitive Load}? This meaning that the device should be easy-to-use. It should not be a complicated pattern to get a task done, but rather a natural way of completing a task. 
 \end{itemize}

\subsubsection{Challenges with VA}
%user acceptance?  

\subsubsection{The different VA in smart speakers}
%Eller kanskje bare skrive om det under her 
As mentioned earlier there are several virtual assistants \cite{hoy.m}. There has been conducted several comparisons between the different assistants; ranging from privacy and security issues \cite{hoy.m} to the reasonable level of personification \cite{Kaye.J} to make the virtual assistant more human-like \cite{Clark.L} to user experience \cite{hoy.m, Lopez.G, Berdasco.A, pyae.a, Kaye.J}. 

%Tror kanskje Hoy.m blir feil i siste setning, han snakker mer overordnet, ikke så mye sammenligning. 

%notater
\textbf{Cortana and Siri are on the bottom - why???? 
This article point us towards making comparison between other virtual assistant than the once listed already} 
\cite{Berdasco.A}

\textbf{Google Assistant: Most natural, less correct. However, when it is not correct it is also not natural (according to the diagram) therefore one could discuss if it therefore is the best verison yet. 
Siri: Least natural, most correct. However, we want someone that is the nearest to Pepper, so that is why we need someone that feels natural to talk with. 
MY OWN OPINION: Alexa has the most user-friendly ux design. 
The tone and pace of the female voice used by the Google device expressed surpise, suspense, and joy. }
\cite{Lopez.G}


\cite{Kaye.J}

%notater

%NB! 
For these literature review the focus will be on user experience with Google Assistant/Home.. 
%NB! 


\subsubsection{Google Assistant}
%nb!når den ikke var korrekt, så var den heller ikke naturlig. Lopez.G

%Notater
Usabilility, user experience, and usefulness - Google Home. %Stikkord fra artikkelen
Usable, user-friendly, efficient, and easy to use. %Stikkord fra artikkelen

Some challenges that were listed (see paper for explaination);
Non-english words are not correctly captured by the device
Sometimes, in using the device, commands have to be repeated to accomplish a task 
Portability of the device and internet connectivity can be an issue
Integration with other systems and devices can be a challenge for users 
Multiple voices can be an issue 
Background noises can be a problem in interacting with the device 
Multiple commands in a single transaction cannot be captured

Shows promises of intertainment, information seeking, and smart home. 
Shows potential for international users, including native and non-native English speakers.
\cite{pyae.a}
%notater


%Hvis dette blir relevant til å eventuelt lage en action i google home elns, eller så trenger vi ikke dette. 
Guidelines: Google Assistant
On Google Developers \cite{GoogleDevelopers} one can find a guide of  designing actions for Google Assistant. They have named this topic; Conversational Design. Here one can also find topics such as “new to conversation design” and “conversation 101”. 
For creating actions one should include design expertise from; VUI design, interaction design, visual design, motion design and UX writing. 
Their “Guideline” consists of \cite{GoogleDevelopers}; 
\begin{itemize}
    \item Designing Process Overview
    \item Finding the Right Voice Interactions
    \item Who are Your users? 
    \item Who is Your Persona?
    \item Draft a Conversation 
    \item Design for Mulitple Devices
    \item Style Guide
    \item Conversational Components 
    \item Error Handling
    \item Visual Components
\end{itemize}
Google’s Guidelines seems to meet the requirements/guidelines that are set by L. M Reeves et. al. \cite{reeves.lm} Google's Guidelines focuses on the user, and have multiple inputs with both adaptivity and feedback. 


\subsection{Human-robot interaction(HRI)}
Human-robot interaction(HRI) is to understand, from designing, evaluation and the robotic system to use by or with humans\cite{etellerannet}. However, Human-centered robots(HCR) design have becoming and more frequently "human friendly", with focus on science and the systems to be able to interact, assist and cooperate with humans.As technology becomes more and more pervasive and need to have a human-centred approach in both design and development of a computer-based systems becoming more relevant and important. For instance, robots in resturants, hopital and service areas (e.g homework robots, entertainment robots, assistive botos, surveillance robots and robots for childrens  education). Some of the biggest challenges on robots is to determine an appropiate and beneficial for the user, from effectiviely design a experience that satisfy the user\cite{Willies}. Human-centered robots aim to understand the relationship between human and robots, with the increased trend towards home services(e.g smart house, smart work place, etc ) and healthcare. With more complex  systems and needs there is need to improve the navigation systems, intelligent control methods and pattern recognition techniques for human-robot interaction to be able to perform in different dynamic environments\cite{He-Li-Chen}.
As new interfaces such as using voice user interface and gesture based interaction are introduced into the market are build. For example, as mentioned earlier in this section, people are getting more used to speak to interaction with their technology by using a VUI. Such as  Amazon Alexa, Google assistants and Apple´s Siri. Robots are also becoming more common (e.g people´s house, offices , etc ) with recent robots for entertainment, assistant and companionship(e.g Aibi, Jibo, Kuri and Pepper). According to Belpaeme, Greef, Baxter and Kennedy \cite{Baxter}, there is very little known about neurological and physhological the foundmental what makes a social human-robot interaction work

\subsubsection{Child-robot interaction (cRI)}
Within the field of Human-computer interaction, cthe interaction between children and robots take a place within this field. Child-robot interaction (cHRI) having a different interaction approach than interaction between adults and robots and children have a different immature  cognitive development \cite{Baxter}. Children does not see robot as machine as a  computer program, but a living system. 
%google mer på cHRI  

\subsection{Social Humanoid Robot:}
%tror jeg bør skrive om hva slags roboter det har blitt brukt tidligere?  Liksom at man skal få en større omfang en det lille jeg sakrev der. eller skrive mer der. 
Social robots are the new type of robots that have one purpose is to interact with humans in a socially way\cite{Lee}. 


When the topic is social robots, it is often the focus are on the communication abilitities without considering the context of which interaction being used. The communication skills does not automatically make them social, and optimize their interaction for a specific task does not make them act more social.  However, properly developing its identity (e.g its knowledge and locate the user and its surrounding environment) providing the robot with the ability  of understand the current social situation, and properly planning and carrying  the interaction. The article discussed by Dignum and Dignum \cite{dignum}, the social context of a intelligent agent  must be considered as the foundation from the start to the end, instead of adding extra condition to be analyzed  from time to time, which can complicate the formalization of agents and robots. 

Robotics technology keeps evolving, according to Kumar and Gelin \cite{Kumar} the next big thing within robotics sector is personal robots. As mentioned earlier robots are becoming more common, r
obots with all kind of shapes and size are entering day-today life, while assisting working and serving (e.g shopping malls, hospitals, museums, railway stations, elder-care facilities, schools, and homes). These various robots being deployed to assist humans in different multimodal ways.

\subsubsection{Physical vs virtual embodiment}


\subsubsection{Robot presence}



\subsubsection{Bruksområder}
%bare mine egne tanker hva  som burde bli nevnt eventuelt. fra tidligere results. ' 
%shopping malls, hospitals, museums, railway stations, elder-care facilities, schools, and homes, museum. Og eventuelt mer hvis jeg finner det ellerno. 




\subsubsection{}
\subsubsection{Challenges with Humanoid/social robot}
%user acceptance? 

%google about spoken dialoge interfaces (SDI)
However,  social humanoids have a long way to go, such machines needs tp ber socially accepted and expected manner. Their need for a robust perception in real environment, the constraints of perceiveing and acting in a real time with the the assigned resources, and the necessity to dynamically interact with different kind of users which create a challenge for developing of a social robot, which requires to look at the challenge from various angles. Another thing is to teach a social humanoid new behaviours, making it  more individually useful, personalized, and adapting to different domains. It reduces the need for context specific development to integrate robots into a new situation\cite{Alexandre}.

AI systems perception remains a bottleneck.

%With the lack of artificial processing and generating appropriate anwers/responses

%child speech recognition

\subsubsection{Pepper}
% hvor aksetabelt er en robot 
%Dette er delen om pepper, regner med at den blir her nede da vi sneverer inn oppgaven tho. 
 In this section, the focus will be on the social humanoid Pepper designed by Aldebaran Robotics and released by SoftbBnk Robotics. Pepper is a advanced humanoid that can be used in various human-centered environment, this is also the idea behind the development of Pepper. For example, social robot Jibo does not have the opportunity to have human body properties like arms. Jibo can only rotate and tilt "his" head and has a fixed spot.
%SLENG INN ET BILDE AV JIBO OR PEPPER. LIKSOM AT POENGET KOMMET FRAM BEDRE MED BILDET. 
Pepper is one of the best options to implementing and research around multimodal in HRI, thanks to sensors, technologies and functionalities already being  preprogrammed in form of API (Application programming interface). Since HRI research domain was to figure out "understand and shape the interaction between humans and robots". A study shows  robots with physical embodients and tactile communication makes more engaging and  better interaction partner than a animated character, and is better supporting for human learning compared to voice or video. 
Pepper have the capabilities of exhibiting body language, understand and interact with its surroundings, and moving around. It can also analyze people´s expressions and voice tunes, by using the latest algorithm in voice and emotions recognition. Pepper is also equipped with features and high level interfaces for multimodal communication with humans around it. The multimodal aspect are primarily intended to recognize peoples presence and avoiding collision with objects during body movement. Since it is designed for a wide range of multimodal (e.g expressive gestures and behavior), it is also equipped with a tablet which makes it easier to interact and development. The design principles of pepper is 
\begin{itemize}
    \item A pleasant appearance
    \item Safety    
    \item Affordability
    \item Interactivity
    \item Good autonomy
\end{itemize}


\subsection{Implementations in the past}

\subsection{}

% --Conclusion--
\section{Conclusion}
